{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0P3TsIg3GhVfrYK+ef8Fp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaveWates/Assignment-ISYS5002/blob/main/Assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtMYsMAcxSIz"
      },
      "source": [
        "# INTRODUCTION:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_umahZQt35P"
      },
      "source": [
        "The meeting today with the client established the parameters for the project.\n",
        "\n",
        "\n",
        "The ATO has enlisted our services to design a program which will web-scrape financial data in the form of Executive Sarlaries from Australian companies, and calculate the tax payable on those salaries. \n",
        "\n",
        "The program must execute on the input of a stock ticker symbol.\n",
        "\n",
        "\n",
        "For ease of reference the department has specified the program is to be saved as either (or both) a CSV or SQLite file.\n",
        "\n",
        "\n",
        "The results will used by the department, for the purposes of an expeditious comparison with historical data, to decide whether there are grounds for further investigation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjnM4j4XxkQJ"
      },
      "source": [
        "#METHODOLOGY:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUfaEyBRydf_"
      },
      "source": [
        "The process we will implore is initially the standard steps:\n",
        "\n",
        "\n",
        "1.   State the problem clearly\n",
        "2. Describe the input and output\n",
        "3. Work a simple example by hand\n",
        "4. Develop an algorithm (and convert into Python)\n",
        "5. Test solution with a variety of data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo3R8AcbNQVL"
      },
      "source": [
        "#THE PROBLEM:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq-ecsvSxRhV"
      },
      "source": [
        "In the examination of what the results are: A set of data that essentially must include the executives name, their title, their reported income, and the tax payable on that income. Additionally this table must be produced, basically from the input of a stock ticker symbol.\n",
        "\n",
        "There appears to be a set of very distinct subsections which need to be addressed:\n",
        "\n",
        "\n",
        "1.   The definition of a \"stock ticker symbol\".\n",
        "2.   Where and how to obtain the information at 1.\n",
        "3.   Where on the web do we find a list of company executives which\n",
        "     includes the other information required.\n",
        "4.   How do we access or scrape this data from the website.\n",
        "5.   How do we calculate the tax payable.\n",
        "6.   How do we present this data in a user friendly manner.\n",
        "7.   How do we save the data in a CSV or SQLite file format.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXtRtL1Lv28D"
      },
      "source": [
        "# RESEARCH:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkMAcM_cUYD6"
      },
      "source": [
        "* What is a stock ticker symbol?\n",
        "\n",
        "> \"A ticker symbol or stock symbol is an abbreviation used to uniquely identify publicly traded shares of a particular stock on a particular stock market.\" https://en.wikipedia.org/wiki/Ticker_symbol\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> The key attributes to take away here is \"a uniuely identifiable   abbreviation\" for a company shares or stocks. And the place or \"particular stock market\" where those shares are traded.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJuiBDRLVC9y"
      },
      "source": [
        "* Where do we find the information in 1?\n",
        "\n",
        "\n",
        "> \"Go to the home page of a financial news website such as MoneyCentral.MSN.com or a financial investment website such as NYSE.com.\" https://budgeting.thenest.com/stock-symbols-companies-4408.html\n",
        "\n",
        "\n",
        "\n",
        "> With the specification of the New York Stock Echange website above,the Australian equivalent of which I am aware is the Australian Stock Exchange. https://www2.asx.com.au\n",
        "\n",
        "\n",
        "\n",
        "* This leads us to the 3rd question which seeks to identify where on the web can we input a ticker symbol and find the type of information required? \n",
        "\n",
        "> Ask the question what are the best \"Stock market websites\"?\n",
        "\n",
        "> Googles answer:\n",
        "\n",
        ">  https://www.google.com/search?client=safari&rls=en&sxsrf=AOaemvIrSubuGSwrEzmaDXjE5hQ2Fe2p0Q:1634174768611&q=Stock+market+websites&stick=H4sIAAAAAAAAAOOQMRItLslPzlbITSzKTi1RKE9NKs4sSS2OKg7PSIRzFfLT0lKLihWKUhNzFEoyc1MVIJoKS_OBahUy8xQSU1IySzLz8xRK8hXSMvMS85IzgUrzUsuLoUqLUotTE4uSMxQS81IUMjKBgkWZyUAlENnkjMSikuJTjFz6ufoGRkWWhjl5pxg5QZxkw_KyJKiESXK5QbwJlGOcnl5elv2LUTQYm_sbWBgXsWKXusUmyXBjJpfp_LhbziZf5rN015_gNvs6Y4deTet3AEaG86EQAQAA&sa=X&ved=2ahUKEwifudW038jzAhUMzTgGHQQ-Cq0Q4qYDegQINBAH&biw=1254&bih=886&dpr=1\n",
        "\n",
        "\n",
        "> The one I recognise is Yahoo Finance.\n",
        "> https://finance.yahoo.com/?fr=sycsrp_catchall\n",
        "\n",
        "> On examination of the website, the information we are looking for does not become immediately obvious.\n",
        "\n",
        "> If you click in the search cell of the page, quite conveniently a list of trending tickers appears. \n",
        "\n",
        "> If you click on one of the tickers you are transported to a page, which after examination is know as the \"Summary\". \n",
        "\n",
        "> How do we know this? Because directly below where the value of the current share price is displayed, is a sub-menu with Summary underlined in blue.\n",
        "\n",
        "> There are various selectable sections in this sub-menu. With some trial and error the selection of \"Profile\" provides exactly the information we are interested in.\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMnnmj7TnO3O"
      },
      "source": [
        "#THE INPUTS AND OUTPUTS:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRkEwOkIn5I7"
      },
      "source": [
        "This question has been answered throught the evaluation of the problem:\n",
        "\n",
        "1.   Inputs: Stock ticker symbol\n",
        "2.   Outputs: A set of data that essentially must include the executives name, their title, their reported income, and the tax payable on that income\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U1Th9iTozzA"
      },
      "source": [
        "# WORK A SIMPLE EXAMPLE BY HAND\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goh9s5PZpdXs"
      },
      "source": [
        "*  **The starting point must be the capability to access the Profile page of the company for which the ticker symbol has been input.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK31oCdOpxHs"
      },
      "source": [
        "I have chosen the major Australian Banks as a test sample.\n",
        "\n",
        "The relevant webpage for the ANZ Bank is:\n",
        "https://au.finance.yahoo.com/quote/ANZ.AX/profile?p=ANZ.AX&.tsrc=fin-srch\n",
        "\n",
        "The relevant webpage for the Commonwealth Bank is:\n",
        "https://au.finance.yahoo.com/quote/CBA.AX/profile?p=CBA.AX&.tsrc=fin-srch\n",
        "\n",
        "The relevant webpage for the National Australia Bank is:\n",
        "https://au.finance.yahoo.com/quote/NAB.AX/profile?p=NAB.AX&.tsrc=fin-srch\n",
        "\n",
        "The relevant webpage for the Westpac Bank is:\n",
        "https://au.finance.yahoo.com/quote/WBC.AX/profile?p=WBC.AX&.tsrc=fin-srch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqhSkGemrwC_"
      },
      "source": [
        "The interesting points to note on comparison of the webpages is:\n",
        "1.   The ticker for each bank includes .ax (Australian Stock Exchange), and\n",
        "2.   The only way in which the URL's are different, is the ticker symbol as specified in the address.\n",
        "\n",
        "This means that we should be able to supply a ticker, which can then be input into the relevant areas of the URL, which will in turn provide access to the page we want.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHD3XRqwtV7P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "171e6de5-7b62-4fe4-e7ef-873a1c6271c6"
      },
      "source": [
        "#By substituting the ticker with curly braces we are creating a dictionary.\n",
        "#A dictionary is a data structure that maps one value to another.\n",
        "#How does this work?\n",
        "#We need the ticker first\n",
        "ticker_symbol = input('What the ticker of the company you like to research?  ')\n",
        "#I have called it template but it could be called anything, and it is the base URL which has the ticker replaced with the braces.\n",
        "template = 'https://au.finance.yahoo.com/quote/{}/profile?p={}&.tsrc=fin-srch'\n",
        "# =To insert the ticker where we want it in the url, we use the format command.\n",
        "url = template.format(ticker_symbol,ticker_symbol)\n",
        "print(url)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What the ticker of the company you like to research?  Anz.ax\n",
            "https://au.finance.yahoo.com/quote/Anz.ax/profile?p=Anz.ax&.tsrc=fin-srch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzUgJ09_xxmj"
      },
      "source": [
        "Once we are happy that the method works we can turn it into a function, which we can call when it is required.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNe5AfteyN96"
      },
      "source": [
        "#Create a function to provide the relevant URL \n",
        "exec_salary_template = ('https://au.finance.yahoo.com/quote/{}/profile?p={}&.tsrc=fin-srch')\n",
        "def get_ticker_symbol():\n",
        " url = exec_salary_template.format(ticker_symbol,ticker_symbol)\n",
        " return url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCm4sus0zUDY"
      },
      "source": [
        "* **Next we have to be able to extract the data we need from the url, this is known as scraping.** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu9XihUU4L-Q"
      },
      "source": [
        "#'''\n",
        "Mr. Shayne Cary Elliott B.Com., B.Com\tMD, CEO & Exec. Director\t3.24M\tN/A\t1964\n",
        "Mr. Mark Whelan\tGroup Exec. of Institutional\t1.59M\tN/A\t1960\n",
        "Mr. Mark Hand\tGroup Exec. Australia Retail & Commercial Banking\t1.81M\tN/A\t1968\n",
        "Ms. Maile Katherine Carnegie\tGroup Exec. of Digital & Australia Transformation\t1.66M\tN/A\t1970\n",
        "Mr. Kevin Paul Corbally\tGroup Chief Risk Officer\t1.57M\tN/A\t1973\n",
        "Mr. Gerard Florian\tGroup Exec. of Technology\t1.49M\tN/A\t1966\n",
        "Ms. Kathryn van der Merwe\tGroup Exec. of Talent & Culture and Service Centres\t1.21M\tN/A\t1974\n",
        "Ms. Antonia Margaret Watson B.Com.\tChief Exec. Officer of New Zealand\t1.38M\tN/A\t1969\n",
        "Mr. Farhan Faruqui\tChief Financial Officer\tN/A\tN/A\t1965\n",
        "Mr. Craig Lioneln Sims MBA\tGroup Gen. Mang. of Operations & Services\tN/A\tN/A\tN/A\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opZFCu9b1Gqn"
      },
      "source": [
        "The above is just an example of the pertinent data and how we would like it to appear. Obvously in addition, ideally we would want tax payable appended to the table.\n",
        "\n",
        "The printout above is purely a \"copy and paste\", a screenshot formatted to appear like a table. \n",
        "\n",
        "We have to develop a function that will extract this data simply by inputing the ticker symbol, then allow manipulation of the data to feed into a tax calculator, which by chance I have already written a function for in a previous project.\n",
        "\n",
        "In order to perform a webscrape we need to import certain libraries. The libraries we have chosen have been selected purely on two criteria, ease of use (lack of complexity) and reliability (failure rate).\n",
        "\n",
        "The tade-off made, is the speed at which the libraries operate. Specifically, Selenium, although almost gauranteed to work, is slow in its operation. \n",
        "\n",
        "These libraries are:\n",
        "*   selenium - \"Selenium refers to a suite of tools that are widely used in the testing community when it comes to cross-browser testing\" (https://www.browserstack.com/guide/selenium-webdriver-tutorial).\n",
        "*   kora - \"This is a collection of tools to make programming on Google Colab easier\" (https://pypi.org/project/kora/).\n",
        "\n",
        "The two together, basically create a webdriver which allows you to interegate a browser by sending commands to that browser and interacting with its applications. \n",
        "\n",
        "In this way we are able to extract information in \"chunks\". As the information is sourced from a web page these chunks are in HTML format. So in order to search and manipulate the data to select the pertinent information.\n",
        "\n",
        "*   \"Beautiful Soup is a Python package for parsing HTML and XML documents \n",
        "(including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping (https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser).\n",
        "\n",
        "Parsing, \"To parse, in computer science, is where a string of commands – usually a program – is separated into more easily processed components, which are analyzed for correct syntax and then attached to tags that define each component (https://www.techopedia.com/definition/3853/parse)\n",
        "\n",
        "Collectively in simple terms, we can search a web page, identify the elements of interest, extract that information and present that in a format that we find useful.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2BDzxXQtU5P"
      },
      "source": [
        "# We use -q to instruct the program not to disply things like copyright and version messages. \n",
        "!pip install kora -q\n",
        "from kora.selenium import wd\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm6dKZ1ExDsU"
      },
      "source": [
        "Steps to follow when scraping:\n",
        "\n",
        "1.   Once the libraries have been imported, we go to the URL of interest and then to the page where the pertinent table data is located. \n",
        " \n",
        "> In the ANZ example we source the yahoo finance ANZ profile page, and the above screenshot will be displayed in its original form.\n",
        "\n",
        "\n",
        "2.   If we were to select anywhere on the page and right-click, a window menu will be displayed which provides an option \"inspect\".\n",
        "\n",
        "> This when selected opens another window to the right of the main page and displays the HTML for the table.\n",
        "\n",
        "3.   Moving the cursor over the HTML block will highlight various elements of the main page (LHS). \n",
        "\n",
        "> On closer examination of the HTML, with reference to what is being highlighted on the main page, it can be seen that the information in the table is represented in the HTML block by various different tags.\n",
        "\n",
        "> These tags form  a \"tree\" with braches connected to sub-tags relating to more detailed infromation within the main table:\n",
        "*   The \"table\" tag highlights the entire table.  \n",
        "*   The \"thead\" tag highlights the header of the table.\n",
        "*   The \"tbody\" tag highlights the information body of the table.\n",
        "*   The \"trclass\" tag highlights the information body of the table.\n",
        "*   The \"tdclass\" tag highlights each column of information.\n",
        "\n",
        "> The r in \"tr\" refers to the row; the \"d\" in the td refers to the data within each rown and column. \n",
        "\n",
        "> For further on the structure of HTML refer: (https://www.w3schools.com/html/html_basic.asp).\n",
        "\n",
        "4.  **Quick summary** - we have developed a function to get the relevant URL, and now we have established the pattern in the HTML of that URL.\n",
        "\n",
        "> How do we extract the infromation?\n",
        "\n",
        "> The webdriver(wd) contained in Selenium will execute a command called get and will access the specifed URL.\n",
        "\n",
        "> We then use BeautifulSoup to parse the HTML, basically break into smaller parts for easy translation into another language.\n",
        "\n",
        "> Because the URL address commences with HTTPS (Hyper Text Transport Protocol System) BeautifulSoup knows it is an HTML page which needs parsing.\n",
        "\n",
        "> Having woorked out the pattern of the HTML, I know we have to narrow the search down by starting at the largest branch of the tree and following it through the smaller ones until we reach the data we are searching for.\n",
        "\n",
        "> This is done first by finding the all tables. In this case there is only 1. If there were more than 1, the speciifcation of table could be find_table[0]. This would find the first table in the list. Remebering computers start counting at 0. So table 2 would be table[1].\n",
        "\n",
        "> From the table tag we then locate the body, then the rows and finally the data in those rows.\n",
        "\n",
        "> The code ends up looking like:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-TaJgH3FxWQ"
      },
      "source": [
        "wd.get('https://au.finance.yahoo.com/quote/Anz.ax/profile?p=Anz.ax&.tsrc=fin-srch')\n",
        "soup = BeautifulSoup(wd.page_source)\n",
        "tables = soup.find_all('table')\n",
        "for table in tables:\n",
        "  body = table.find('tbody')\n",
        "  rows = body.find_all('tr')\n",
        "  for row in rows:\n",
        "    data = row.find_all('td')\n",
        "    for txt in data:\n",
        "      print(txt.text)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgeYVonjW7g3"
      },
      "source": [
        "\n",
        "5. The output is all the information but includes superfluous items which are not required, like date of birth.\n",
        "\n",
        "> We can now develop a function based on the above, to scrape the page and provide an output which contains only the items of information we want - name, title and pay; by creating a list and appending those items only.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saeGok6NYaeO"
      },
      "source": [
        "def get_records(soup):\n",
        "  ''' This function extracts the row from an HTML table'''\n",
        "  table = soup.find('table')\n",
        "  body = table.find('tbody')\n",
        "  rows = body.find_all('tr')\n",
        "  list_of_records = [] # Create a empty list to save/store our records\n",
        "  for row in rows:\n",
        "    data = row.find_all('td')\n",
        "    data = [x.text.strip() for x in data] # This esures that only the text is returned, without the tag information.\n",
        "    # Remember start counting from zero, so the 'first' item is '0'\n",
        "    record = {'name': data[0], 'title': data[1], 'pay': data[2]}\n",
        "    list_of_records.append(record)  # Save the required items to our list\n",
        "    \n",
        "  return list_of_records"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofljFvMudFr0"
      },
      "source": [
        "6. From reviewing the output of our list, it can be seen that the pay or salary is shown as a number followed by a letter such as \"M\" for million or \"k\" for thousands.\n",
        "\n",
        "> Obviously in order for the tax calculator to work, it requires whole numbers only. \"2.54 M\" will generate an error.\n",
        "\n",
        "> Thus we need to able to convert the text into a useable number.\n",
        "\n",
        "> The use of \"-1\" causes Python to start at the last character of a list.\n",
        "\n",
        "> eg., List = [3, 2, 1]\n",
        "\n",
        ">    List[-1] = 1\n",
        "\n",
        "\n",
        ">    [0:-1] = returns everything but the last character.\n",
        "\n",
        "\n",
        "> In the list we have created from the scrape, \"pay\" is the item we need to correct.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYTjlMCxogox",
        "outputId": "c51b6d9b-4b4f-4b02-b843-9af5fdc3026b"
      },
      "source": [
        "pay = ('2.54M') # Appears as a string\n",
        "last_char = pay[-1] # Selects the M\n",
        "num_part = pay[0:-1] # States that the number is everything but M\n",
        "if last_char == 'M':\n",
        "    salary = float(num_part) * 1000000 # Converts the number to a float\n",
        "elif last_char == 'k': \n",
        "    salary = float(num_part) * 1000\n",
        "else:\n",
        "    salary = 0\n",
        "print(salary)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2540000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atH7hPYKrl_W"
      },
      "source": [
        "As the logic in the program is true, we can now convert this into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Bv2t1NsK64"
      },
      "source": [
        "def get_salary(salary_string):\n",
        "   ''' This function takes a string, and removes the last \n",
        "   character then converts the remainder into a number '''\n",
        "   last_char = salary_string[-1] \n",
        "   num_part = salary_string[0:-1]\n",
        "   if last_char == 'M':\n",
        "        salary = float(num_part) * 1000000\n",
        "   elif last_char == 'k': \n",
        "        salary = float(num_part) * 1000\n",
        "   else: # Must a N/A entry\n",
        "        salary = 0\n",
        "   return salary"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTHnajnZtL_M"
      },
      "source": [
        "7. The final part of the process is to introduce the tax calculation function. As already mentioned this function was created in a previous project and "
      ]
    }
  ]
}